tasks:
  vqa: true
  captioning: true
data:
  captioning:
    dataset_path: /content/drive/MyDrive/DS Data&Notebooks/Data/Image_Captioning_COCO-2014/
    train_input: /content/drive/MyDrive/DS Data&Notebooks/Data/Image_Captioning_COCO-2014/captioning.json
    train_output: /content/drive/MyDrive/DS Data&Notebooks/Data/Image_Captioning_COCO-2014/captioning_answers.json
    val_input: /content/drive/MyDrive/DS Data&Notebooks/Data/Image_Captioning_COCO-2014/captioning_val.json
    val_output: /content/drive/MyDrive/DS Data&Notebooks/Data/Image_Captioning_COCO-2014/captioning_val_answer.json
  vqa:
    dataset_path: /content/drive/MyDrive/DS Data&Notebooks/Data/VQA_VisualGenome/
    train_input: /content/drive/MyDrive/DS Data&Notebooks/Data/VQA_VisualGenome/vqa_train.json
    train_output: /content/drive/MyDrive/DS Data&Notebooks/Data/VQA_VisualGenome/vqa_train_answer.json
    val_input: /content/drive/MyDrive/DS Data&Notebooks/Data/VQA_VisualGenome/vqa_val.json
    val_output: /content/drive/MyDrive/DS Data&Notebooks/Data/VQA_VisualGenome/vqa_val_answer.json
model:
  rudolph:
    name: 350M
    fp16: false
    device: cpu
    cache_dir: /tmp/rudolph
    pretrained: false
  from_checkoint: true
  rudolph_weight: /content/drive/MyDrive/DS Data&Notebooks/Ru-DOLPH/outputs/checkpoints/checkpoints_2tasks_rudolph-350M-v3
    (1)/last.ckpt
  vae:
    dwt: false
  params:
    num_layers: 24
    hidden_size: 1024
    num_attention_heads: 16
    tasks: [captioning, vqa]
    embedding_dropout_prob: 0.1
    output_dropout_prob: 0.1
    attention_dropout_prob: 0.1
    l_text_seq_length: 64
    image_tokens_per_dim: 16
    r_text_seq_length: 64
    kernel_size: 7
    last_kernel_size: 9
    cogview_sandwich_layernorm: true
    cogview_pb_relax: true
    text_special_tokens: 384
    image_special_tokens: 384
    vocab_size: 16448
    image_vocab_size: 8192
    mlp_activation: gelu_jit
bs: 2
